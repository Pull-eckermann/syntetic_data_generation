\chapter{Experimentos}

%=====================================================

Para garantir a capacidade de generalização dos modelos, os experimentos conduzidos neste trabalho são realizados em cenários cruzados, levando em conta as bases CNRPark-EXT \citet{cnrpark} e PKLot \citep{pklot2}. Ou seja, o padrão definido é sempre treinar o modelo em uma das bases e validar em outra, realizando a adição ou não das imagens sintéticas. Para isso, quatro principais cenários foram considerados em relação ao treinamento dos modelos, todos utilizando o processo de aprendizado por transferência:
\begin{itemize}
    \item M1 - Modelos treinados somente com imagens reais
    \item M2 - Modelos treinados somente com imagens sintéticas
    \item M3 - Modelos treinados com imagens reais adicionadas de todas as imagens sintéticas geradas
    \item M4 - Modelos treinados com imagens reais adicionadas de uma base de imagens sintéticas específica para um cenário (Um modelo para cada câmera da base que vai ser usada para validação)
\end{itemize}

As bases com imagens reais (PKLot e CNRPark-EXT) são ordenadas em ordem crescente dos dias de captura e divididas na proporção de 70\% para treino e 30\% para teste em cada dia. O modelo de apenas imagens sintéticas soma todas as imagens as divide na mesma  proporção, 70\% das imagens totais para treino e 30\% para teste durante o treinamento. Aos modelos que usam a mistura entre imagens reais e sintéticas, soma-se as imagens do subconjunto de treino da base real as imagens sintéticas (Específicas de um cenário ou todas juntas). No total, 17 modelos foram treinados e utilizados nos experimentos.

Cada modelo foi treinado por 15 épocas utilizando o otimizador Adam, uma taxa de aprendizado de 0.0001 e um “batch size” de 32. Após as 15 épocas, o modelo que apresentou menor taxa de “loss” (Calculada por pela “Binary Crossentropy”) é escolhido e salvo. Cada modelo foi treinado e validado 3 vezes, e a média das 3 execuções é o resultado final. Para a classificação, o limiar de decisão é calculado de acordo com o Equal Error Rate no espaço ROC. Esses parâmetros foram escolhidos por meio de experimentação e foram os que apresentaram melhores resultados.

\section{Resultados}

Os modelos treinados foram validados para cada subconjunto das bases de imagens reais. O resultado geral do modelo é calculado pela média aritmética entre entre os resultados das acurácias. A tabela {tab:tabela-resultados-1} e {tab:tabela-resultados-2} mostram as acurácias obtidas com os tipos de modelos M1, M2 e M3 treinados. Podemos ver que os melhores resultados foram alcançados pelos modelos treinado com imagens reais, com uma acurácia média de 96,9\% para a validação com os subconjuntos da PKLot e 94,6\% para a validação com os subconjuntos da CNRPark-EXT. Enquanto isso o modelo treinado somente com imagens sintéticas teve um resultado bem inferior na validação dos subconjuntos da PKlot, porém teve um resultado aproximado do modelo treinado com imagens reais, tratando da validação com os subconjuntos da CNRPark-EXT. Já o modelo onde o treinamento usou como base a mistura entre as imagens reais e um conjunto geral das imagens sintéticas não apresentou uma mudança significativa nos resultados. Isso pode se dar ao fato de haverem muitas imagens o que faz o modelo convergir para o mesmo resultado.

\begin{table}[!htp] \footnotesize
    \centering
    \caption{Acuŕacias obtidas validando com os subconjuntos da PKLot os tipos de modelos M1, M2 e M3}
    \label{tab:tabela-resultados-1}
    \begin{tabular}{cccc}
    \texttt{} &  & Treino &  \\
    \cline{2-4}
    \multicolumn{1}{c|}{Teste}& CNRPark-EXT Real & Somente Imagens sintéticas & CNRPark-EXT + imagens sintéticas da PKlot \\
    \hline
    \texttt{PKLot-UFPR04} & 0,94752605273849 & 0,772077511030488 & 0,942348572886255 \\
    \hline
    \texttt{PKLot-UFPR05} & 0,97867720240070 & 0,874697147912456 & 0,973924058268239 \\
    \hline
    \texttt{PKLot-PUCPR} & 0,980970700158485 & 0,788663980972271 & 0,982081751028743 \\
    \hline
    \texttt{Média} & \textbf{0,969057985099225} & \textbf{0,811812879971738} & \textbf{0,966118127394412} \\
    \hline
    \end{tabular}
\end{table}

\begin{table}[!htp] \footnotesize
    \centering
    \caption{Acuŕacias obtidas validando com os subconjuntos da CNRPark-EXT os tipos de modelos M1, M2 e M3}
    \label{tab:tabela-resultados-2}
    \begin{tabular}{cccc}
    \texttt{} &  & Treino &  \\
    \cline{2-4}
    \multicolumn{1}{c|}{Teste}& PKLot Real & Somente Imagens sintéticas & PKLot + imagens sintéticas da CNRPark-EXT \\
    \hline
    \texttt{CNR-cam1} & 0,927117665679757 & 0,914231979591456 & 0,914623019198182 \\
    \hline
    \texttt{CNR-cam2} & 0,958979885057471 & 0,973922413793103 & 0,959410919540229 \\
    \hline
    \texttt{CNR-cam3} & 0,958506616257089 & 0,935601764335223 & 0,939193446754883 \\
    \hline
    \texttt{CNR-cam4} & 0,959827189586489 & 0,937141147206792 & 0,955824870485702 \\
    \hline
    \texttt{CNR-cam5} & 0,941338490389123 & 0,943301687763712 & 0,949953117674636 \\
    \hline
    \texttt{CNR-cam6} & 0,935086980920314 & 0,926613355780022 & 0,938959034792368 \\
    \hline
    \texttt{CNR-cam7} & 0,94483970136144 & 0,94312692138779 & 0,94770897379593 \\
    \hline
    \texttt{CNR-cam8} & 0,944815927873779 & 0,935975457049837 & 0,961244678186826 \\
    \hline
    \texttt{CNR-cam9} & 0,950823474831825 & 0,947483182556251 & 0,955277197865924 \\
    \hline
    \texttt{Média} & \textbf{0,946815103550810} & \textbf{0,939710878829354} & \textbf{0,946910584254965} \\
    \hline
    \end{tabular}
\end{table}

A tabela \ref{tab:tabela-resultados-3} disponibiliza os resultados obtidos com os modelos treinados da mistura das imagens reais com as imagens sintéticas específicas de cada cenário. Podemos ver que na maioria dos casos alguma melhora na acurácia é notada, em no resultado geral pode-se ver uma melhora de cerca de 0,5\% em comparação aos resultados obtidos apenas com as imagens reais, explicitados nas tabelas \ref{tab:tabela-resultados-1} e \ref{tab:tabela-resultados-2}.

\begin{table}[!htp] \footnotesize
    \centering
    \caption{Acuŕacias obtidas com os modelos treinados com imagens sintéticas de cenários específicos}
    \label{tab:tabela-resultados-3}
    \begin{tabular}{cc}
    \texttt{Modelo}& Teste CNRPark-EXT Cenário específico \\
    \hline
    \texttt{PKLot + CNR-cam1 sintético} & 0,918160994847615 \\
    \hline
    \texttt{PKLot + CNR-cam2 sintético} & \textbf{0,972341954022988} \\
    \hline
    \texttt{PKLot + CNR-cam3 sintético} & 0,944316318035125 \\
    \hline
    \texttt{PKLot + CNR-cam4 sintético} & 0,960032920042673 \\
    \hline
    \texttt{PKLot + CNR-cam5 sintético} & \textbf{0,948898255825042} \\
    \hline
    \texttt{PKLot + CNR-cam6 sintético} & \textbf{0,946787317593892} \\
    \hline
    \texttt{PKLot + CNR-cam7 sintético} & 0,943587473392486 \\
    \hline
    \texttt{PKLot + CNR-cam8 sintético} & \textbf{0,961895817680941} \\
    \hline
    \texttt{PKLot + CNR-cam9 sintético} & \textbf{0,956692179044087} \\
    \hline
    \texttt{Média} & \textbf{0,950301470053872} \\
    \hline
    \hline
    \texttt{Modelo}& Teste PKLot Cenário específico \\
    \hline
    \texttt{CNRPark-EXT + PKLot-UFPR04} & \textbf{0,959084052165313} \\
    \hline
    \texttt{CNRPark-EXT + PKLot-UFPR05} & \textbf{0,980392275135466} \\
    \hline
    \texttt{CNRPark-EXT + PKLot-PUCPR} & \textbf{0,983244661416283} \\
    \hline
    \texttt{Média} & \textbf{0,974240329572354} \\
    \hline
    \end{tabular}
\end{table}

\section{Análise dos resultados}

O modelo base e o método de treinamento (“Transfer learning”) escolhido evidenciaram a boa capacidade de generalização do modelo e apresentaram resultados próximos e comparáveis a outros trabalhos no estado da arte que tratam desse mesmo problema. Assim, podemos ter uma boa base de comparação na avaliação do desempenho das imagens sintéticas de baixa fidelidade ao se utilizar os resultados obtidos com tipos de modelos M1 treinados. Pode-se concluir então:

P1 - Qual o impacto das imagens sintéticas de baixa fidelidade na eficiência dos modelos estado da arte de classificação de vagas de estacionamento em cenários cruzados? Os tipos de modelo M3, em comparação com o M1 não apresentaram resultados satisfatórios, mantendo-se com resultados próximos ou inferiores. Esse resultado pode ser justificado pela quantidade de imagens sintéticas que são utilizadas nesse método, o que acaba generalizando mais o modelo e perdendo a capacidade de especificação do cenário que está sendo validado no momento, convergindo para o resultado obtido apenas com imagens reais. Já os modelos do tipo M4 apresentaram uma melhora no geral de 0,5\% em comparação com os modelos M1, sendo maiores que 1\% para alguns casos. Isso pode ter se dado pelo fato de os subconjuntos utilizados para o treinamento desses modelos possuírem menos imagens, e ao adicionar as imagens sintéticas específicas de um cenário às imagens reais o modelo acaba adquirindo a capacidade de especificação daquele cenário e não se confunde. Isso evidencia que os modelos do tipo M4 são a melhor abordagem para se resolver o problema de especificar o modelo para um cenário sem a necessidade de dados reais, e talvez possam apresentar resultados ainda melhores ao se utilizar de imagens sintéticas fotorealistas.

P2 - É possível superar o estado da arte treinando os modelos somente com imagens sintéticas de baixa fidelidade? Não. As acurácias obtidas com os modelos de tipo M2 foram consideravelmente inferiores às obtidas com os modelos de tipo M1. Isso pode ter acontecido pois as imagens sintéticas de baixa fidelidade não apresentam características realistas o suficiente para se resolver o problema de classificação de vagas de estacionamento, como não reproduzir fielmente a qualidade da imagem e detalhes das condições climáticas e de iluminação. Talvez a melhor abordagem para a criação de um modelo somente com imagens sintéticas que possa competir com o estado da arte seja a descrita em \citet{objectPose}, que consiste em misturar imagens sintéticas altamente randomizadas com imagens sintéticas fotorealísticas.
%=====================================================
