\chapter{Estado da Arte}

%=====================================================
% 3 - Estado da arte
% 3.1 Como são criados os modelos de machine learning para classificar vagas hoje em dia?
% Comece com a PKLot e CNRPark-EXT.
% 3.2 Como são gerados dados sintéticos hoje em dia, e qual os resultados geralmente obtidos?

Uma das maiores limitações dos modelos de classificação baseados em aprendizado de máquina é lidar com a falta de dados. Uma forma de contornar o problema da falta de dados é a utilização de dados sintéticos \citep{synthetic-pedestrians} \citep{domain-random}. Neste capítulo serão discutidos os métodos atuais de machine learning para classificação de vagas de estacionamento, as bases de dados disponíveis e também como são gerados os dados sintéticos hoje em dia e quais os resultados obtidos.

\section{Bases de dados}

A base de dados PKLot \citep{pklot2} é comumente usada para pesquisas em detecção e classificação de vagas de estacionamento por meio de visão computacional \citep{heat-map}\citep{hochuli-2}\citep{systematic-review}. Contém 12.417 imagens de tamanho 1280X720 capturadas de dois estacionamentos diferentes (UFPR e PUCPR) em dias ensolarados, nublados e chuvosos. O primeiro estacionamento possui dois ângulos de captura diferentes (UFPR04 e UFPR05). Cada imagem possui anotações das posições das vagas e cada vaga está associada a um rótulo indicando se está ocupada ou vazia. Usando essas anotações e segmentando as imagens, é possível ter cerca de 695,900 imagens de vagas de estacionamento nas mais diversas condições. Essa diversidade é valiosa para treinar e avaliar modelos de aprendizado de máquina e visão computacional, permitindo o desenvolvimento de sistemas robustos capazes de identificar automaticamente a ocupação de vagas em estacionamentos com base nas imagens fornecidas \citep{pklot2}\citep{systematic-review}\citep{hochuli-2}.

Outra base de dados comumente usada em pesquisas é a CNRPark-EXT \citet{cnrpark}. Especificamente, é uma expansão do conjunto de dados CNRPark, que foi desenvolvido para avaliar e treinar algoritmos de reconhecimento de ocupação de vagas em estacionamentos. É composta por 12,000 imagens capturadas por câmeras instaladas em 9 diferentes ambientes de estacionamento, cada imagem com anotações de segmentação das vagas com seus respectivos rótulos, entre ocupada ou livre, gerando cerca de 150,000 imagens rotuladas. As imagens apresentam variações em iluminação, condições climáticas e diferentes ângulos de visualização, tornando o conjunto de dados desafiador e representativo de situações do mundo real.

\section{Métodos de classificação}

O trabalho de \citet{pklot2} propõe o uso de características LPQ e LBP extraídas das imagens como vetores de características e SVMs como classificadores. Conjuntos de SVMs treinados utilizando diversas variações dos métodos LPQ/LBP como características foram utilizados para classificação. Este método resultou em desempenhos satisfatórios, contudo revelou limitações em termos de generalização. Em geral, ao treinar um classificador com um subconjunto de imagens de um determinado estacionamento e testá-lo com outro subconjunto do mesmo estacionamento, alcançamos consistentemente uma acurácia média de aproximadamente 99,5\%, praticamente atingindo 100\%. No entanto, no cenário de validação cruzada entre os subsets, a acurácia média caiu para cerca de 85\%. Essa redução na precisão ao lidar com dados de estacionamentos distintos sugere que o método pode ser eficaz dentro do mesmo contexto de estacionamento, mas enfrenta dificuldades na generalização para diferentes ambientes ou cenários.

Em \citet{hochuli-1} vemos o uso de modelos de Deep Learning. O questionamento foi elevado a outro nível, com o objetivo de determinar o impacto do tipo de segmentação (Retângulos rotacionados, bounding-boxes e polígonos) das vagas nos resultados e também medir a quantidade de imagens necessárias para aperfeiçoar um modelo para cenários específicos. Para isso, foi definida uma CNN pré-treinada composta por 3 camadas convolucionais. Os experimentos revelaram acurácias superiores a 99% para os cenários específicos (modelo treinado e testado no mesmo subset), atingindo os melhores resultados para o tipo de segmentação com retângulos rotacionados. Além disso, provou-se que com apenas 1000 imagens é possível realizar a afinação do modelo pré-treinado e obter resultados satisfatórios na mudança de cenários.

Considerando o tempo e esforço necessários para a coleta de imagens, segmentação das vagas e anotação dos rótulos, em \citet{hochuli-2} diversos modelos e técnicas são testadas a fim de validar qual modelo se conmporta melhor num cenário de validação cruzada. É então concluído que um modelo global com a arquitetura da MobileNetv3 \citep{MobileNetV3} é adequada para a classificação de vagas de estacionamento em diferentes cenários e é capaz de atingir uma taxa de acerto de em média 95% nos cenários de validação cruzada, dispensando assim a necessidade de fine-tuning em cenários em que a coleta de imagens é restrita.

Mesmo com esses resultados, o problema de classificação de vagas de estacionamento ainda carece de mais imagens para validação e treinamento de modelos. Nesse contexto, técnicas de geração de imagens sintéticas podem ser usadas tanto no treinamento como na validação de modelos, para tentar melhorar a acurácia de um modelo para um cenário global ou específico.

\section{Geração de dados Sintéticos}

Os dados sintéticos são gerados artificialmente e algoritmicamente e são empregados no treinamento de modelos de machine learning para complementar conjuntos de dados existentes ou compensar a falta de dados reais. Eles desempenham um papel crucial ao aumentar a diversidade e a quantidade de amostras disponíveis, especialmente em cenários onde os conjuntos de dados são limitados ou insuficientes. Além disso, esses dados podem ser úteis na representação de situações raras, na preservação da privacidade dos dados reais, na redução de vieses nos conjuntos de dados e na criação de cenários de teste e validação para garantir a robustez dos modelos de machine learning.

Diversas ferramentas podem ser utilizadas para a geração de dados sintéticos. Com relação a imagens sintéticas, as ferramentas mais utilizadas são motores gráficos e engines de jogos como Unity e Unreal Engine. Dando destaque às engines de jogos, existem pacotes personalizados que auxiliam na aleatorização, captura e rotulação dos dados, como é o caso do Unity perception \citep{unity-perception}, para o Unity3d, e o NDDS \citep{NDDS} para a Unreal Engine 4.

Entretanto, existem algumas barreiras quando se trata de utilizar dados sintéticos para treinamento. O "Reality Gap" \citep{domain-random}, conhecido como a lacuna entre ambientes sintéticos e a complexidade do mundo real, resulta na dificuldade dos modelos treinados apenas com dados sintéticos em se adaptarem adequadamente a situações reais. Essa discrepância surge devido à complexidade em simular fielmente todas as características visuais, físicas e dinâmicas do mundo real nos dados sintéticos. Elementos como iluminação, texturas, variações climáticas e interações complexas são desafios para a reprodução precisa. Consequentemente, modelos treinados exclusivamente com dados sintéticos podem ter dificuldade em generalizar para situações reais. Uma estratégia para superar essa limitação é combinar dados sintéticos e reais durante o treinamento, oferecendo ao modelo uma exposição mais diversificada e possibilitando uma melhor adaptação e desempenho em cenários do mundo real. Outras técnicas também estão presentes na literatura.

O conceito de domain-randomization \citep{domain-random}, envolve introduzir aleatoriedade deliberada nos ambientes de treinamento sintéticos usados para ensinar modelos de machine learning, principalmente com imagens. Essa técnica visa criar uma variedade maior de cenários, ajustando aleatoriamente parâmetros como texturas, iluminação e formas geométricas. Ao variar aleatoriamente as características do ambiente virtual os modelos são expostos a uma ampla gama de condições durante o treinamento. Essa diversidade ajuda os modelos a se adaptarem a diferentes variações que podem ser encontradas no mundo real, capacitando-os a generalizar de forma mais eficaz para situações reais. Em essência, ao simular uma maior variedade de cenários durante o treinamento, os modelos se tornam mais robustos e capazes de lidar com a complexidade e as variações do mundo real, diminuindo a diferença entre os ambientes virtuais e o mundo real.

O estudo de \citet{domain-random} demonstrou que um detector de objetos treinado exclusivamente em simulação utilizando a técnica de domain randomization pode atingir uma precisão suficientemente alta no mundo real, possibilitando a realização de agarramentos em ambientes com obstáculos. 

Em \citet{objectPose} foi demonstrado que a combinação de imagens sintéticas não fotorealistas (Domain Randomization) com imagens sintéticas fotorealistas, para o treinamento de redes neurais, pode superar com sucesso o problema de reality-gap para aplicações no mundo real, alcançando desempenho comparável com redes de última geração treinadas em dados reais.

A combinação de imagens fotorealísticas e domain randomization no treinamento de modelos de deep learning é eficiente porque atenua a diferença entre ambientes sintéticos e o mundo real. Enquanto as imagens fotorealísticas replicam detalhes visuais precisos do mundo real, o domain randomization introduz variações controladas ou aleatórias nos ambientes virtuais. Essa abordagem amplia a diversidade dos dados de treinamento, permitindo que os modelos se adaptem a uma variedade de condições presentes na prática, fortalecendo sua capacidade de generalização para situações reais ao minimizar a lacuna da realidade durante o treinamento.

%=====================================================
